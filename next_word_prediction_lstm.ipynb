{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Next Word Predictor using LSTM"
      ],
      "metadata": {
        "id": "sVqO3eL8r6Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhHbnPJnrreR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NfcpnluzLzo",
        "outputId": "7aec7c4b-d366-4426-c864-c5fa149cc72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import all the libraries"
      ],
      "metadata": {
        "id": "tWfsLQXzrV5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ],
      "metadata": {
        "id": "ae7dunqczT8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and Data Preprocessing"
      ],
      "metadata": {
        "id": "cpIQ_lC1sOpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filename = '/content/drive/MyDrive/aaa.txt'\n",
        "\n",
        "# read the text file\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    document = f.read()\n",
        "\n",
        "\n",
        "\n",
        "# remove unnecessary Project Gutenberg header/footer\n",
        "# find story start\n",
        "start_idx = document.find('To Sherlock Holmes she is always')\n",
        "if start_idx == -1:\n",
        "    start_idx = document.find('A SCANDAL IN BOHEMIA')\n",
        "if start_idx == -1:\n",
        "    start_idx = 0\n",
        "\n",
        "# find story end\n",
        "end_idx = document.find('End of the Project Gutenberg')\n",
        "if end_idx == -1:\n",
        "    end_idx = document.find('END OF THE PROJECT GUTENBERG')\n",
        "if end_idx == -1:\n",
        "    end_idx = len(document)\n",
        "\n",
        "# extract only the story content\n",
        "document = document[start_idx:end_idx]\n",
        "\n",
        "print(f\"Extracted story: {len(document)} characters\")\n",
        "print(f\"Preview: {document[:200]}\")\n",
        "\n",
        "\n",
        "\n",
        "# remove commas\n",
        "document = document.replace(\",\", \"\")\n",
        "\n",
        "# split by periods\n",
        "input_sentences = document.split('.')\n",
        "input_sentences = [s.strip() for s in input_sentences if s.strip()]\n",
        "\n"
      ],
      "metadata": {
        "id": "fLwm0Y_MzVuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e99f32-02a4-4d46-c75d-c96251121f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted story: 561606 characters\n",
            "Preview: To Sherlock Holmes she is always _the_ woman. I have seldom heard him\n",
            "mention her under any other name. In his eyes she eclipses and\n",
            "predominates the whole of her sex. It was not that he felt any emot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Tokenization and Vocabulary Building"
      ],
      "metadata": {
        "id": "JXBGqdP6scS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download nltk data for word tokenization\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMU_RwfbzXt4",
        "outputId": "48735792-c979-4c1e-f6e9-3902978c7f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text\n",
        "tokens = word_tokenize(document.lower())"
      ],
      "metadata": {
        "id": "t28bgAcszaHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "vocab = {'<unk>':0}\n",
        "\n",
        "for token in Counter(tokens).keys():\n",
        "  if token not in vocab:\n",
        "    vocab[token] = len(vocab)\n",
        "\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G30GxEjgzcfY",
        "outputId": "07fb9bde-7b5b-419f-8ab0-1cf8f6d47733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 0,\n",
              " 'to': 1,\n",
              " 'sherlock': 2,\n",
              " 'holmes': 3,\n",
              " 'she': 4,\n",
              " 'is': 5,\n",
              " 'always': 6,\n",
              " '_the_': 7,\n",
              " 'woman': 8,\n",
              " '.': 9,\n",
              " 'i': 10,\n",
              " 'have': 11,\n",
              " 'seldom': 12,\n",
              " 'heard': 13,\n",
              " 'him': 14,\n",
              " 'mention': 15,\n",
              " 'her': 16,\n",
              " 'under': 17,\n",
              " 'any': 18,\n",
              " 'other': 19,\n",
              " 'name': 20,\n",
              " 'in': 21,\n",
              " 'his': 22,\n",
              " 'eyes': 23,\n",
              " 'eclipses': 24,\n",
              " 'and': 25,\n",
              " 'predominates': 26,\n",
              " 'the': 27,\n",
              " 'whole': 28,\n",
              " 'of': 29,\n",
              " 'sex': 30,\n",
              " 'it': 31,\n",
              " 'was': 32,\n",
              " 'not': 33,\n",
              " 'that': 34,\n",
              " 'he': 35,\n",
              " 'felt': 36,\n",
              " 'emotion': 37,\n",
              " 'akin': 38,\n",
              " 'love': 39,\n",
              " 'for': 40,\n",
              " 'irene': 41,\n",
              " 'adler': 42,\n",
              " 'all': 43,\n",
              " 'emotions': 44,\n",
              " 'one': 45,\n",
              " 'particularly': 46,\n",
              " 'were': 47,\n",
              " 'abhorrent': 48,\n",
              " 'cold': 49,\n",
              " 'precise': 50,\n",
              " 'but': 51,\n",
              " 'admirably': 52,\n",
              " 'balanced': 53,\n",
              " 'mind': 54,\n",
              " 'take': 55,\n",
              " 'most': 56,\n",
              " 'perfect': 57,\n",
              " 'reasoning': 58,\n",
              " 'observing': 59,\n",
              " 'machine': 60,\n",
              " 'world': 61,\n",
              " 'has': 62,\n",
              " 'seen': 63,\n",
              " 'as': 64,\n",
              " 'a': 65,\n",
              " 'lover': 66,\n",
              " 'would': 67,\n",
              " 'placed': 68,\n",
              " 'himself': 69,\n",
              " 'false': 70,\n",
              " 'position': 71,\n",
              " 'never': 72,\n",
              " 'spoke': 73,\n",
              " 'softer': 74,\n",
              " 'passions': 75,\n",
              " 'save': 76,\n",
              " 'with': 77,\n",
              " 'gibe': 78,\n",
              " 'sneer': 79,\n",
              " 'they': 80,\n",
              " 'admirable': 81,\n",
              " 'things': 82,\n",
              " 'observer—excellent': 83,\n",
              " 'drawing': 84,\n",
              " 'veil': 85,\n",
              " 'from': 86,\n",
              " 'men': 87,\n",
              " '’': 88,\n",
              " 's': 89,\n",
              " 'motives': 90,\n",
              " 'actions': 91,\n",
              " 'trained': 92,\n",
              " 'reasoner': 93,\n",
              " 'admit': 94,\n",
              " 'such': 95,\n",
              " 'intrusions': 96,\n",
              " 'into': 97,\n",
              " 'own': 98,\n",
              " 'delicate': 99,\n",
              " 'finely': 100,\n",
              " 'adjusted': 101,\n",
              " 'temperament': 102,\n",
              " 'introduce': 103,\n",
              " 'distracting': 104,\n",
              " 'factor': 105,\n",
              " 'which': 106,\n",
              " 'might': 107,\n",
              " 'throw': 108,\n",
              " 'doubt': 109,\n",
              " 'upon': 110,\n",
              " 'mental': 111,\n",
              " 'results': 112,\n",
              " 'grit': 113,\n",
              " 'sensitive': 114,\n",
              " 'instrument': 115,\n",
              " 'or': 116,\n",
              " 'crack': 117,\n",
              " 'high-power': 118,\n",
              " 'lenses': 119,\n",
              " 'be': 120,\n",
              " 'more': 121,\n",
              " 'disturbing': 122,\n",
              " 'than': 123,\n",
              " 'strong': 124,\n",
              " 'nature': 125,\n",
              " 'yet': 126,\n",
              " 'there': 127,\n",
              " 'late': 128,\n",
              " 'dubious': 129,\n",
              " 'questionable': 130,\n",
              " 'memory': 131,\n",
              " 'had': 132,\n",
              " 'little': 133,\n",
              " 'lately': 134,\n",
              " 'my': 135,\n",
              " 'marriage': 136,\n",
              " 'drifted': 137,\n",
              " 'us': 138,\n",
              " 'away': 139,\n",
              " 'each': 140,\n",
              " 'complete': 141,\n",
              " 'happiness': 142,\n",
              " 'home-centred': 143,\n",
              " 'interests': 144,\n",
              " 'rise': 145,\n",
              " 'up': 146,\n",
              " 'around': 147,\n",
              " 'man': 148,\n",
              " 'who': 149,\n",
              " 'first': 150,\n",
              " 'finds': 151,\n",
              " 'master': 152,\n",
              " 'establishment': 153,\n",
              " 'sufficient': 154,\n",
              " 'absorb': 155,\n",
              " 'attention': 156,\n",
              " 'while': 157,\n",
              " 'loathed': 158,\n",
              " 'every': 159,\n",
              " 'form': 160,\n",
              " 'society': 161,\n",
              " 'bohemian': 162,\n",
              " 'soul': 163,\n",
              " 'remained': 164,\n",
              " 'our': 165,\n",
              " 'lodgings': 166,\n",
              " 'baker': 167,\n",
              " 'street': 168,\n",
              " 'buried': 169,\n",
              " 'among': 170,\n",
              " 'old': 171,\n",
              " 'books': 172,\n",
              " 'alternating': 173,\n",
              " 'week': 174,\n",
              " 'between': 175,\n",
              " 'cocaine': 176,\n",
              " 'ambition': 177,\n",
              " 'drowsiness': 178,\n",
              " 'drug': 179,\n",
              " 'fierce': 180,\n",
              " 'energy': 181,\n",
              " 'keen': 182,\n",
              " 'still': 183,\n",
              " 'ever': 184,\n",
              " 'deeply': 185,\n",
              " 'attracted': 186,\n",
              " 'by': 187,\n",
              " 'study': 188,\n",
              " 'crime': 189,\n",
              " 'occupied': 190,\n",
              " 'immense': 191,\n",
              " 'faculties': 192,\n",
              " 'extraordinary': 193,\n",
              " 'powers': 194,\n",
              " 'observation': 195,\n",
              " 'following': 196,\n",
              " 'out': 197,\n",
              " 'those': 198,\n",
              " 'clues': 199,\n",
              " 'clearing': 200,\n",
              " 'mysteries': 201,\n",
              " 'been': 202,\n",
              " 'abandoned': 203,\n",
              " 'hopeless': 204,\n",
              " 'official': 205,\n",
              " 'police': 206,\n",
              " 'time': 207,\n",
              " 'some': 208,\n",
              " 'vague': 209,\n",
              " 'account': 210,\n",
              " 'doings': 211,\n",
              " ':': 212,\n",
              " 'summons': 213,\n",
              " 'odessa': 214,\n",
              " 'case': 215,\n",
              " 'trepoff': 216,\n",
              " 'murder': 217,\n",
              " 'singular': 218,\n",
              " 'tragedy': 219,\n",
              " 'atkinson': 220,\n",
              " 'brothers': 221,\n",
              " 'at': 222,\n",
              " 'trincomalee': 223,\n",
              " 'finally': 224,\n",
              " 'mission': 225,\n",
              " 'accomplished': 226,\n",
              " 'so': 227,\n",
              " 'delicately': 228,\n",
              " 'successfully': 229,\n",
              " 'reigning': 230,\n",
              " 'family': 231,\n",
              " 'holland': 232,\n",
              " 'beyond': 233,\n",
              " 'these': 234,\n",
              " 'signs': 235,\n",
              " 'activity': 236,\n",
              " 'however': 237,\n",
              " 'merely': 238,\n",
              " 'shared': 239,\n",
              " 'readers': 240,\n",
              " 'daily': 241,\n",
              " 'press': 242,\n",
              " 'knew': 243,\n",
              " 'former': 244,\n",
              " 'friend': 245,\n",
              " 'companion': 246,\n",
              " 'night—it': 247,\n",
              " 'on': 248,\n",
              " 'twentieth': 249,\n",
              " 'march': 250,\n",
              " '1888—i': 251,\n",
              " 'returning': 252,\n",
              " 'journey': 253,\n",
              " 'patient': 254,\n",
              " '(': 255,\n",
              " 'now': 256,\n",
              " 'returned': 257,\n",
              " 'civil': 258,\n",
              " 'practice': 259,\n",
              " ')': 260,\n",
              " 'when': 261,\n",
              " 'way': 262,\n",
              " 'led': 263,\n",
              " 'me': 264,\n",
              " 'through': 265,\n",
              " 'passed': 266,\n",
              " 'well-remembered': 267,\n",
              " 'door': 268,\n",
              " 'must': 269,\n",
              " 'associated': 270,\n",
              " 'wooing': 271,\n",
              " 'dark': 272,\n",
              " 'incidents': 273,\n",
              " 'scarlet': 274,\n",
              " 'seized': 275,\n",
              " 'desire': 276,\n",
              " 'see': 277,\n",
              " 'again': 278,\n",
              " 'know': 279,\n",
              " 'how': 280,\n",
              " 'employing': 281,\n",
              " 'rooms': 282,\n",
              " 'brilliantly': 283,\n",
              " 'lit': 284,\n",
              " 'even': 285,\n",
              " 'looked': 286,\n",
              " 'saw': 287,\n",
              " 'tall': 288,\n",
              " 'spare': 289,\n",
              " 'figure': 290,\n",
              " 'pass': 291,\n",
              " 'twice': 292,\n",
              " 'silhouette': 293,\n",
              " 'against': 294,\n",
              " 'blind': 295,\n",
              " 'pacing': 296,\n",
              " 'room': 297,\n",
              " 'swiftly': 298,\n",
              " 'eagerly': 299,\n",
              " 'head': 300,\n",
              " 'sunk': 301,\n",
              " 'chest': 302,\n",
              " 'hands': 303,\n",
              " 'clasped': 304,\n",
              " 'behind': 305,\n",
              " 'mood': 306,\n",
              " 'habit': 307,\n",
              " 'attitude': 308,\n",
              " 'manner': 309,\n",
              " 'told': 310,\n",
              " 'their': 311,\n",
              " 'story': 312,\n",
              " 'work': 313,\n",
              " 'risen': 314,\n",
              " 'drug-created': 315,\n",
              " 'dreams': 316,\n",
              " 'hot': 317,\n",
              " 'scent': 318,\n",
              " 'new': 319,\n",
              " 'problem': 320,\n",
              " 'rang': 321,\n",
              " 'bell': 322,\n",
              " 'shown': 323,\n",
              " 'chamber': 324,\n",
              " 'formerly': 325,\n",
              " 'part': 326,\n",
              " 'effusive': 327,\n",
              " ';': 328,\n",
              " 'glad': 329,\n",
              " 'think': 330,\n",
              " 'hardly': 331,\n",
              " 'word': 332,\n",
              " 'spoken': 333,\n",
              " 'kindly': 334,\n",
              " 'eye': 335,\n",
              " 'waved': 336,\n",
              " 'an': 337,\n",
              " 'armchair': 338,\n",
              " 'threw': 339,\n",
              " 'across': 340,\n",
              " 'cigars': 341,\n",
              " 'indicated': 342,\n",
              " 'spirit': 343,\n",
              " 'gasogene': 344,\n",
              " 'corner': 345,\n",
              " 'then': 346,\n",
              " 'stood': 347,\n",
              " 'before': 348,\n",
              " 'fire': 349,\n",
              " 'over': 350,\n",
              " 'introspective': 351,\n",
              " 'fashion': 352,\n",
              " '“': 353,\n",
              " 'wedlock': 354,\n",
              " 'suits': 355,\n",
              " 'you': 356,\n",
              " '”': 357,\n",
              " 'remarked': 358,\n",
              " 'watson': 359,\n",
              " 'put': 360,\n",
              " 'seven': 361,\n",
              " 'half': 362,\n",
              " 'pounds': 363,\n",
              " 'since': 364,\n",
              " 'you.': 365,\n",
              " '!': 366,\n",
              " 'answered': 367,\n",
              " 'indeed': 368,\n",
              " 'should': 369,\n",
              " 'thought': 370,\n",
              " 'just': 371,\n",
              " 'trifle': 372,\n",
              " 'fancy': 373,\n",
              " 'observe': 374,\n",
              " 'did': 375,\n",
              " 'tell': 376,\n",
              " 'intended': 377,\n",
              " 'go': 378,\n",
              " 'harness.': 379,\n",
              " 'do': 380,\n",
              " '?': 381,\n",
              " 'deduce': 382,\n",
              " 'getting': 383,\n",
              " 'yourself': 384,\n",
              " 'very': 385,\n",
              " 'wet': 386,\n",
              " 'clumsy': 387,\n",
              " 'careless': 388,\n",
              " 'servant': 389,\n",
              " 'girl': 390,\n",
              " 'dear': 391,\n",
              " 'said': 392,\n",
              " 'this': 393,\n",
              " 'too': 394,\n",
              " 'much': 395,\n",
              " 'certainly': 396,\n",
              " 'burned': 397,\n",
              " 'lived': 398,\n",
              " 'few': 399,\n",
              " 'centuries': 400,\n",
              " 'ago': 401,\n",
              " 'true': 402,\n",
              " 'country': 403,\n",
              " 'walk': 404,\n",
              " 'thursday': 405,\n",
              " 'came': 406,\n",
              " 'home': 407,\n",
              " 'dreadful': 408,\n",
              " 'mess': 409,\n",
              " 'changed': 410,\n",
              " 'clothes': 411,\n",
              " 'can': 412,\n",
              " 't': 413,\n",
              " 'imagine': 414,\n",
              " 'mary': 415,\n",
              " 'jane': 416,\n",
              " 'incorrigible': 417,\n",
              " 'wife': 418,\n",
              " 'given': 419,\n",
              " 'notice': 420,\n",
              " 'fail': 421,\n",
              " 'out.': 422,\n",
              " 'chuckled': 423,\n",
              " 'rubbed': 424,\n",
              " 'long': 425,\n",
              " 'nervous': 426,\n",
              " 'together': 427,\n",
              " 'simplicity': 428,\n",
              " 'itself': 429,\n",
              " 'inside': 430,\n",
              " 'your': 431,\n",
              " 'left': 432,\n",
              " 'shoe': 433,\n",
              " 'where': 434,\n",
              " 'firelight': 435,\n",
              " 'strikes': 436,\n",
              " 'leather': 437,\n",
              " 'scored': 438,\n",
              " 'six': 439,\n",
              " 'almost': 440,\n",
              " 'parallel': 441,\n",
              " 'cuts': 442,\n",
              " 'obviously': 443,\n",
              " 'caused': 444,\n",
              " 'someone': 445,\n",
              " 'carelessly': 446,\n",
              " 'scraped': 447,\n",
              " 'round': 448,\n",
              " 'edges': 449,\n",
              " 'sole': 450,\n",
              " 'order': 451,\n",
              " 'remove': 452,\n",
              " 'crusted': 453,\n",
              " 'mud': 454,\n",
              " 'hence': 455,\n",
              " 'double': 456,\n",
              " 'deduction': 457,\n",
              " 'vile': 458,\n",
              " 'weather': 459,\n",
              " 'malignant': 460,\n",
              " 'boot-slitting': 461,\n",
              " 'specimen': 462,\n",
              " 'london': 463,\n",
              " 'slavey': 464,\n",
              " 'if': 465,\n",
              " 'gentleman': 466,\n",
              " 'walks': 467,\n",
              " 'smelling': 468,\n",
              " 'iodoform': 469,\n",
              " 'black': 470,\n",
              " 'mark': 471,\n",
              " 'nitrate': 472,\n",
              " 'silver': 473,\n",
              " 'right': 474,\n",
              " 'forefinger': 475,\n",
              " 'bulge': 476,\n",
              " 'side': 477,\n",
              " 'top-hat': 478,\n",
              " 'show': 479,\n",
              " 'secreted': 480,\n",
              " 'stethoscope': 481,\n",
              " 'dull': 482,\n",
              " 'pronounce': 483,\n",
              " 'active': 484,\n",
              " 'member': 485,\n",
              " 'medical': 486,\n",
              " 'profession.': 487,\n",
              " 'could': 488,\n",
              " 'help': 489,\n",
              " 'laughing': 490,\n",
              " 'ease': 491,\n",
              " 'explained': 492,\n",
              " 'process': 493,\n",
              " 'hear': 494,\n",
              " 'give': 495,\n",
              " 'reasons': 496,\n",
              " 'thing': 497,\n",
              " 'appears': 498,\n",
              " 'ridiculously': 499,\n",
              " 'simple': 500,\n",
              " 'easily': 501,\n",
              " 'myself': 502,\n",
              " 'though': 503,\n",
              " 'successive': 504,\n",
              " 'instance': 505,\n",
              " 'am': 506,\n",
              " 'baffled': 507,\n",
              " 'until': 508,\n",
              " 'explain': 509,\n",
              " 'believe': 510,\n",
              " 'are': 511,\n",
              " 'good': 512,\n",
              " 'yours.': 513,\n",
              " 'quite': 514,\n",
              " 'lighting': 515,\n",
              " 'cigarette': 516,\n",
              " 'throwing': 517,\n",
              " 'down': 518,\n",
              " 'distinction': 519,\n",
              " 'clear': 520,\n",
              " 'example': 521,\n",
              " 'frequently': 522,\n",
              " 'steps': 523,\n",
              " 'lead': 524,\n",
              " 'hall': 525,\n",
              " 'room.': 526,\n",
              " 'frequently.': 527,\n",
              " 'often': 528,\n",
              " 'well': 529,\n",
              " 'hundreds': 530,\n",
              " 'times.': 531,\n",
              " 'many': 532,\n",
              " 'don': 533,\n",
              " 'know.': 534,\n",
              " 'observed': 535,\n",
              " 'point': 536,\n",
              " 'seventeen': 537,\n",
              " 'because': 538,\n",
              " 'both': 539,\n",
              " 'interested': 540,\n",
              " 'problems': 541,\n",
              " 'enough': 542,\n",
              " 'chronicle': 543,\n",
              " 'two': 544,\n",
              " 'trifling': 545,\n",
              " 'experiences': 546,\n",
              " 'may': 547,\n",
              " 'this.': 548,\n",
              " 'sheet': 549,\n",
              " 'thick': 550,\n",
              " 'pink-tinted': 551,\n",
              " 'notepaper': 552,\n",
              " 'lying': 553,\n",
              " 'open': 554,\n",
              " 'table': 555,\n",
              " 'last': 556,\n",
              " 'post': 557,\n",
              " 'read': 558,\n",
              " 'aloud.': 559,\n",
              " 'note': 560,\n",
              " 'undated': 561,\n",
              " 'without': 562,\n",
              " 'either': 563,\n",
              " 'signature': 564,\n",
              " 'address': 565,\n",
              " 'will': 566,\n",
              " 'call': 567,\n",
              " 'to-night': 568,\n",
              " 'quarter': 569,\n",
              " 'eight': 570,\n",
              " 'o': 571,\n",
              " 'clock': 572,\n",
              " 'desires': 573,\n",
              " 'consult': 574,\n",
              " 'matter': 575,\n",
              " 'deepest': 576,\n",
              " 'moment': 577,\n",
              " 'recent': 578,\n",
              " 'services': 579,\n",
              " 'royal': 580,\n",
              " 'houses': 581,\n",
              " 'europe': 582,\n",
              " 'safely': 583,\n",
              " 'trusted': 584,\n",
              " 'matters': 585,\n",
              " 'importance': 586,\n",
              " 'exaggerated': 587,\n",
              " 'we': 588,\n",
              " 'quarters': 589,\n",
              " 'received': 590,\n",
              " 'hour': 591,\n",
              " 'amiss': 592,\n",
              " 'visitor': 593,\n",
              " 'wear': 594,\n",
              " 'mask.': 595,\n",
              " 'mystery': 596,\n",
              " 'what': 597,\n",
              " 'means': 598,\n",
              " 'no': 599,\n",
              " 'data': 600,\n",
              " 'capital': 601,\n",
              " 'mistake': 602,\n",
              " 'theorise': 603,\n",
              " 'insensibly': 604,\n",
              " 'begins': 605,\n",
              " 'twist': 606,\n",
              " 'facts': 607,\n",
              " 'suit': 608,\n",
              " 'theories': 609,\n",
              " 'instead': 610,\n",
              " 'carefully': 611,\n",
              " 'examined': 612,\n",
              " 'writing': 613,\n",
              " 'paper': 614,\n",
              " 'written': 615,\n",
              " 'wrote': 616,\n",
              " 'presumably': 617,\n",
              " 'endeavouring': 618,\n",
              " 'imitate': 619,\n",
              " 'processes': 620,\n",
              " 'bought': 621,\n",
              " 'crown': 622,\n",
              " 'packet': 623,\n",
              " 'peculiarly': 624,\n",
              " 'stiff.': 625,\n",
              " 'peculiar—that': 626,\n",
              " 'english': 627,\n",
              " 'hold': 628,\n",
              " 'light.': 629,\n",
              " 'large': 630,\n",
              " 'e': 631,\n",
              " 'small': 632,\n",
              " 'g': 633,\n",
              " 'p': 634,\n",
              " 'woven': 635,\n",
              " 'texture': 636,\n",
              " 'make': 637,\n",
              " 'asked': 638,\n",
              " 'maker': 639,\n",
              " 'monogram': 640,\n",
              " 'rather.': 641,\n",
              " '‘': 642,\n",
              " 'stands': 643,\n",
              " 'gesellschaft': 644,\n",
              " 'german': 645,\n",
              " 'company.': 646,\n",
              " 'customary': 647,\n",
              " 'contraction': 648,\n",
              " 'like': 649,\n",
              " 'co.': 650,\n",
              " 'course': 651,\n",
              " 'papier.': 652,\n",
              " 'eg.': 653,\n",
              " 'let': 654,\n",
              " 'glance': 655,\n",
              " 'continental': 656,\n",
              " 'gazetteer.': 657,\n",
              " 'took': 658,\n",
              " 'heavy': 659,\n",
              " 'brown': 660,\n",
              " 'volume': 661,\n",
              " 'shelves': 662,\n",
              " 'eglow': 663,\n",
              " 'eglonitz—here': 664,\n",
              " 'egria': 665,\n",
              " 'german-speaking': 666,\n",
              " 'country—in': 667,\n",
              " 'bohemia': 668,\n",
              " 'far': 669,\n",
              " 'carlsbad': 670,\n",
              " 'remarkable': 671,\n",
              " 'being': 672,\n",
              " 'scene': 673,\n",
              " 'death': 674,\n",
              " 'wallenstein': 675,\n",
              " 'its': 676,\n",
              " 'numerous': 677,\n",
              " 'glass-factories': 678,\n",
              " 'paper-mills.': 679,\n",
              " 'ha': 680,\n",
              " 'boy': 681,\n",
              " 'sparkled': 682,\n",
              " 'sent': 683,\n",
              " 'great': 684,\n",
              " 'blue': 685,\n",
              " 'triumphant': 686,\n",
              " 'cloud': 687,\n",
              " 'made': 688,\n",
              " 'precisely': 689,\n",
              " 'peculiar': 690,\n",
              " 'construction': 691,\n",
              " 'sentence—': 692,\n",
              " 'received.': 693,\n",
              " 'frenchman': 694,\n",
              " 'russian': 695,\n",
              " 'uncourteous': 696,\n",
              " 'verbs': 697,\n",
              " 'only': 698,\n",
              " 'remains': 699,\n",
              " 'therefore': 700,\n",
              " 'discover': 701,\n",
              " 'wanted': 702,\n",
              " 'writes': 703,\n",
              " 'prefers': 704,\n",
              " 'wearing': 705,\n",
              " 'mask': 706,\n",
              " 'showing': 707,\n",
              " 'face': 708,\n",
              " 'here': 709,\n",
              " 'comes': 710,\n",
              " 'mistaken': 711,\n",
              " 'resolve': 712,\n",
              " 'doubts.': 713,\n",
              " 'sharp': 714,\n",
              " 'sound': 715,\n",
              " 'horses': 716,\n",
              " 'hoofs': 717,\n",
              " 'grating': 718,\n",
              " 'wheels': 719,\n",
              " 'curb': 720,\n",
              " 'followed': 721,\n",
              " 'pull': 722,\n",
              " 'whistled': 723,\n",
              " 'pair': 724,\n",
              " 'yes': 725,\n",
              " 'continued': 726,\n",
              " 'glancing': 727,\n",
              " 'window': 728,\n",
              " 'nice': 729,\n",
              " 'brougham': 730,\n",
              " 'beauties': 731,\n",
              " 'hundred': 732,\n",
              " 'fifty': 733,\n",
              " 'guineas': 734,\n",
              " 'apiece': 735,\n",
              " 'money': 736,\n",
              " 'nothing': 737,\n",
              " 'else.': 738,\n",
              " 'better': 739,\n",
              " 'holmes.': 740,\n",
              " 'bit': 741,\n",
              " 'doctor': 742,\n",
              " 'stay': 743,\n",
              " 'lost': 744,\n",
              " 'boswell': 745,\n",
              " 'promises': 746,\n",
              " 'interesting': 747,\n",
              " 'pity': 748,\n",
              " 'miss': 749,\n",
              " 'it.': 750,\n",
              " 'client—': 751,\n",
              " 'want': 752,\n",
              " 'sit': 753,\n",
              " 'best': 754,\n",
              " 'attention.': 755,\n",
              " 'slow': 756,\n",
              " 'step': 757,\n",
              " 'stairs': 758,\n",
              " 'passage': 759,\n",
              " 'paused': 760,\n",
              " 'immediately': 761,\n",
              " 'outside': 762,\n",
              " 'loud': 763,\n",
              " 'authoritative': 764,\n",
              " 'tap': 765,\n",
              " 'come': 766,\n",
              " 'entered': 767,\n",
              " 'less': 768,\n",
              " 'feet': 769,\n",
              " 'inches': 770,\n",
              " 'height': 771,\n",
              " 'limbs': 772,\n",
              " 'hercules': 773,\n",
              " 'dress': 774,\n",
              " 'rich': 775,\n",
              " 'richness': 776,\n",
              " 'england': 777,\n",
              " 'bad': 778,\n",
              " 'taste': 779,\n",
              " 'bands': 780,\n",
              " 'astrakhan': 781,\n",
              " 'slashed': 782,\n",
              " 'sleeves': 783,\n",
              " 'fronts': 784,\n",
              " 'double-breasted': 785,\n",
              " 'coat': 786,\n",
              " 'deep': 787,\n",
              " 'cloak': 788,\n",
              " 'thrown': 789,\n",
              " 'shoulders': 790,\n",
              " 'lined': 791,\n",
              " 'flame-coloured': 792,\n",
              " 'silk': 793,\n",
              " 'secured': 794,\n",
              " 'neck': 795,\n",
              " 'brooch': 796,\n",
              " 'consisted': 797,\n",
              " 'single': 798,\n",
              " 'flaming': 799,\n",
              " 'beryl': 800,\n",
              " 'boots': 801,\n",
              " 'extended': 802,\n",
              " 'halfway': 803,\n",
              " 'calves': 804,\n",
              " 'trimmed': 805,\n",
              " 'tops': 806,\n",
              " 'fur': 807,\n",
              " 'completed': 808,\n",
              " 'impression': 809,\n",
              " 'barbaric': 810,\n",
              " 'opulence': 811,\n",
              " 'suggested': 812,\n",
              " 'appearance': 813,\n",
              " 'carried': 814,\n",
              " 'broad-brimmed': 815,\n",
              " 'hat': 816,\n",
              " 'hand': 817,\n",
              " 'wore': 818,\n",
              " 'upper': 819,\n",
              " 'extending': 820,\n",
              " 'past': 821,\n",
              " 'cheekbones': 822,\n",
              " 'vizard': 823,\n",
              " 'apparently': 824,\n",
              " 'raised': 825,\n",
              " 'lower': 826,\n",
              " 'appeared': 827,\n",
              " 'character': 828,\n",
              " 'hanging': 829,\n",
              " 'lip': 830,\n",
              " 'straight': 831,\n",
              " 'chin': 832,\n",
              " 'suggestive': 833,\n",
              " 'resolution': 834,\n",
              " 'pushed': 835,\n",
              " 'length': 836,\n",
              " 'obstinacy': 837,\n",
              " 'harsh': 838,\n",
              " 'voice': 839,\n",
              " 'strongly': 840,\n",
              " 'marked': 841,\n",
              " 'accent': 842,\n",
              " 'call.': 843,\n",
              " 'uncertain': 844,\n",
              " 'pray': 845,\n",
              " 'seat': 846,\n",
              " 'colleague': 847,\n",
              " 'dr.': 848,\n",
              " 'occasionally': 849,\n",
              " 'cases': 850,\n",
              " 'whom': 851,\n",
              " 'honour': 852,\n",
              " 'count': 853,\n",
              " 'von': 854,\n",
              " 'kramm': 855,\n",
              " 'nobleman': 856,\n",
              " 'understand': 857,\n",
              " 'discretion': 858,\n",
              " 'trust': 859,\n",
              " 'extreme': 860,\n",
              " 'prefer': 861,\n",
              " 'communicate': 862,\n",
              " 'alone.': 863,\n",
              " 'rose': 864,\n",
              " 'caught': 865,\n",
              " 'wrist': 866,\n",
              " 'back': 867,\n",
              " 'chair': 868,\n",
              " 'none': 869,\n",
              " 'say': 870,\n",
              " 'anything': 871,\n",
              " 'me.': 872,\n",
              " 'shrugged': 873,\n",
              " 'broad': 874,\n",
              " 'begin': 875,\n",
              " 'binding': 876,\n",
              " 'absolute': 877,\n",
              " 'secrecy': 878,\n",
              " 'years': 879,\n",
              " 'end': 880,\n",
              " 'present': 881,\n",
              " 'weight': 882,\n",
              " 'influence': 883,\n",
              " 'european': 884,\n",
              " 'history.': 885,\n",
              " 'promise': 886,\n",
              " 'i.': 887,\n",
              " 'excuse': 888,\n",
              " 'strange': 889,\n",
              " 'august': 890,\n",
              " 'person': 891,\n",
              " 'employs': 892,\n",
              " 'wishes': 893,\n",
              " 'agent': 894,\n",
              " 'unknown': 895,\n",
              " 'confess': 896,\n",
              " 'once': 897,\n",
              " 'title': 898,\n",
              " 'called': 899,\n",
              " 'exactly': 900,\n",
              " 'own.': 901,\n",
              " 'aware': 902,\n",
              " 'dryly': 903,\n",
              " 'circumstances': 904,\n",
              " 'delicacy': 905,\n",
              " 'precaution': 906,\n",
              " 'taken': 907,\n",
              " 'quench': 908,\n",
              " 'grow': 909,\n",
              " 'scandal': 910,\n",
              " 'seriously': 911,\n",
              " 'compromise': 912,\n",
              " 'families': 913,\n",
              " 'speak': 914,\n",
              " 'plainly': 915,\n",
              " 'implicates': 916,\n",
              " 'house': 917,\n",
              " 'ormstein': 918,\n",
              " 'hereditary': 919,\n",
              " 'kings': 920,\n",
              " 'bohemia.': 921,\n",
              " 'also': 922,\n",
              " 'murmured': 923,\n",
              " 'settling': 924,\n",
              " 'closing': 925,\n",
              " 'glanced': 926,\n",
              " 'apparent': 927,\n",
              " 'surprise': 928,\n",
              " 'languid': 929,\n",
              " 'lounging': 930,\n",
              " 'depicted': 931,\n",
              " 'incisive': 932,\n",
              " 'energetic': 933,\n",
              " 'slowly': 934,\n",
              " 'reopened': 935,\n",
              " 'impatiently': 936,\n",
              " 'gigantic': 937,\n",
              " 'client': 938,\n",
              " 'majesty': 939,\n",
              " 'condescend': 940,\n",
              " 'state': 941,\n",
              " 'able': 942,\n",
              " 'advise': 943,\n",
              " 'sprang': 944,\n",
              " 'paced': 945,\n",
              " 'uncontrollable': 946,\n",
              " 'agitation': 947,\n",
              " 'gesture': 948,\n",
              " 'desperation': 949,\n",
              " 'tore': 950,\n",
              " 'hurled': 951,\n",
              " 'ground': 952,\n",
              " 'cried': 953,\n",
              " 'king': 954,\n",
              " 'why': 955,\n",
              " 'attempt': 956,\n",
              " 'conceal': 957,\n",
              " 'addressing': 958,\n",
              " 'wilhelm': 959,\n",
              " 'gottsreich': 960,\n",
              " 'sigismond': 961,\n",
              " 'grand': 962,\n",
              " 'duke': 963,\n",
              " 'cassel-felstein': 964,\n",
              " 'sitting': 965,\n",
              " 'passing': 966,\n",
              " 'high': 967,\n",
              " 'white': 968,\n",
              " 'forehead': 969,\n",
              " 'accustomed': 970,\n",
              " 'doing': 971,\n",
              " 'business': 972,\n",
              " 'confide': 973,\n",
              " 'putting': 974,\n",
              " 'power': 975,\n",
              " '_incognito_': 976,\n",
              " 'prague': 977,\n",
              " 'purpose': 978,\n",
              " 'consulting': 979,\n",
              " 'shutting': 980,\n",
              " 'briefly': 981,\n",
              " 'five': 982,\n",
              " 'during': 983,\n",
              " 'lengthy': 984,\n",
              " 'visit': 985,\n",
              " 'warsaw': 986,\n",
              " 'acquaintance': 987,\n",
              " 'well-known': 988,\n",
              " 'adventuress': 989,\n",
              " 'familiar': 990,\n",
              " 'look': 991,\n",
              " 'index': 992,\n",
              " 'opening': 993,\n",
              " 'adopted': 994,\n",
              " 'system': 995,\n",
              " 'docketing': 996,\n",
              " 'paragraphs': 997,\n",
              " 'concerning': 998,\n",
              " 'difficult': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOOEZ94P0dQ1",
        "outputId": "956416d5-7f68-4faf-83b0-8eb75fb4818d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9058"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = document.split('\\n')"
      ],
      "metadata": {
        "id": "RefNavJe1Cva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Convert Text to Numerical Sequences"
      ],
      "metadata": {
        "id": "xjboI-xvsyXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_indices(sentence, vocab):\n",
        "\n",
        "  numerical_sentence = []\n",
        "\n",
        "  for token in sentence:\n",
        "    if token in vocab:\n",
        "      numerical_sentence.append(vocab[token])\n",
        "    else:\n",
        "      numerical_sentence.append(vocab['<unk>'])\n",
        "\n",
        "  return numerical_sentence\n"
      ],
      "metadata": {
        "id": "x52A3E1K1zjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert each sentence to numerical indices\n",
        "input_numerical_sentences = []\n",
        "\n",
        "for sentence in input_sentences:\n",
        "  input_numerical_sentences.append(text_to_indices(word_tokenize(sentence.lower()), vocab))\n",
        "\n",
        "print(f\"Total numerical sentences: {len(input_numerical_sentences)}\")\n",
        "print(f\"Sample: {input_numerical_sentences[0][:10]}\")"
      ],
      "metadata": {
        "id": "eu66Zo3e1Wh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b953eb79-cf61-4f04-be32-3712af577d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total numerical sentences: 11880\n",
            "Sample: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_numerical_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxJesAQC1et3",
        "outputId": "1ea5a9d2-d6f7-4c47-f61e-f738b8d6d24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11880"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Convert training sequences"
      ],
      "metadata": {
        "id": "RUgQf2SstOmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create training pair: [input_seq] -> [next_word]\n",
        "training_sequence = []\n",
        "for sentence in input_numerical_sentences:\n",
        "\n",
        "  for i in range(1, len(sentence)):\n",
        "    training_sequence.append(sentence[:i+1])"
      ],
      "metadata": {
        "id": "80rIx4aq6ele"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aGJ0fy7swk",
        "outputId": "763cde16-599e-4000-e1ca-e084b18a6269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109352"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequence[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrFzZ4DD8Anu",
        "outputId": "c54de820-46c4-41cd-ad08-b4c4f1666d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find the longest sequence for padding\n",
        "len_list = []\n",
        "\n",
        "for sequence in training_sequence:\n",
        "  len_list.append(len(sequence))\n",
        "\n",
        "max_len_list = max(len_list)\n",
        "max_len_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2Z_fiVZ8GRo",
        "outputId": "14769e5f-cca8-4244-d594-036a50d72aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad all sequences to the same length with zeros\n",
        "padded_training_sequence = []\n",
        "for sequence in training_sequence:\n",
        "\n",
        "  # add zeros to the left to reach max_len_list\n",
        "  padded_training_sequence.append([0]*(max_len_list - len(sequence)) + sequence)"
      ],
      "metadata": {
        "id": "dtPg5uRN9Cc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(padded_training_sequence[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqZssF989X-4",
        "outputId": "32e1d02a-4e72-4adc-fb17-9d78ae5b947e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to Pytorch tensor\n",
        "padded_training_sequence = torch.tensor(padded_training_sequence, dtype=torch.long)"
      ],
      "metadata": {
        "id": "0_wVpepb9iE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_training_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvdXa79yxV",
        "outputId": "f57b418c-6cbe-4ba9-fc9d-4c59eac48b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ...,    0,    1,    2],\n",
              "        [   0,    0,    0,  ...,    1,    2,    3],\n",
              "        [   0,    0,    0,  ...,    2,    3,    4],\n",
              "        ...,\n",
              "        [   0,    0,    0,  ..., 2394,   77, 2187],\n",
              "        [   0,    0,    0,  ...,   77, 2187, 1207],\n",
              "        [   0,    0,    0,  ..., 2187, 1207,    9]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Prepare Training Data\n"
      ],
      "metadata": {
        "id": "3vPvgw8fuYVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_training_sequence[:, :-1]\n",
        "y = padded_training_sequence[:,-1]"
      ],
      "metadata": {
        "id": "Tz8fwCok90m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ed_PLHJ-Dgv",
        "outputId": "2afd21a8-65fc-468c-d7a4-4f0a3fabdc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    0,    0,  ...,    0,    0,    1],\n",
              "        [   0,    0,    0,  ...,    0,    1,    2],\n",
              "        [   0,    0,    0,  ...,    1,    2,    3],\n",
              "        ...,\n",
              "        [   0,    0,    0,  ...,   62, 2394,   77],\n",
              "        [   0,    0,    0,  ..., 2394,   77, 2187],\n",
              "        [   0,    0,    0,  ...,   77, 2187, 1207]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eReVrcX9-EUU",
        "outputId": "1fcc63c7-4349-4ace-e184-56d85848e3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,    3,    4,  ..., 2187, 1207,    9])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create customdataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "fR059hVd-IAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X,y)"
      ],
      "metadata": {
        "id": "KLX0clQM_j9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYHaeSuI_nJX",
        "outputId": "41fbf598-3a16-4943-cd4d-dcda0ab3d2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109352"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create DataLoader for batch processing\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "7ZUeD3l6_oZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Build LSTM model"
      ],
      "metadata": {
        "id": "_FyjXqwSu-Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 100)\n",
        "    self.lstm = nn.LSTM(100, 150, batch_first=True)\n",
        "    self.fc = nn.Linear(150, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n",
        "    output = self.fc(final_hidden_state.squeeze(0))\n",
        "    return output"
      ],
      "metadata": {
        "id": "0TEukXmWDEn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UkzdnI5kvRRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### initialize model"
      ],
      "metadata": {
        "id": "ousZw4AOvoxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model instance\n",
        "model = LSTMModel(len(vocab))"
      ],
      "metadata": {
        "id": "YcQEVc9aVgr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device if GPU available otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Lvm7W6L1X6P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# move model to device\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXwq43NRYD3q",
        "outputId": "20a3899f-e7ac-47f1-fd66-c94e22f15d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(9058, 100)\n",
              "  (lstm): LSTM(100, 150, batch_first=True)\n",
              "  (fc): Linear(in_features=150, out_features=9058, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Training setup"
      ],
      "metadata": {
        "id": "lI6nmBE6vvqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training hyperparameters\n",
        "epochs = 60\n",
        "learning_rate = 0.001\n",
        "\n",
        "# losss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1faORN1VYFdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for batch_x, batch_y in dataloader:\n",
        "\n",
        "    # move batch to device\n",
        "    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    output = model(batch_x)\n",
        "\n",
        "    # calculate loss\n",
        "    loss = criterion(output, batch_y)\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # update weight\n",
        "    optimizer.step()\n",
        "\n",
        "    # accumulate loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch + 1}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRLc1cbrYVVV",
        "outputId": "50feb626-e7e2-4e12-ce8e-84b7ad29a829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 16561.3758\n",
            "Epoch: 2, Loss: 14949.4622\n",
            "Epoch: 3, Loss: 13606.5530\n",
            "Epoch: 4, Loss: 12431.0909\n",
            "Epoch: 5, Loss: 11386.0895\n",
            "Epoch: 6, Loss: 10445.5018\n",
            "Epoch: 7, Loss: 9622.3985\n",
            "Epoch: 8, Loss: 8884.0947\n",
            "Epoch: 9, Loss: 8230.8399\n",
            "Epoch: 10, Loss: 7644.6325\n",
            "Epoch: 11, Loss: 7121.8116\n",
            "Epoch: 12, Loss: 6654.6276\n",
            "Epoch: 13, Loss: 6236.3300\n",
            "Epoch: 14, Loss: 5859.8556\n",
            "Epoch: 15, Loss: 5517.4938\n",
            "Epoch: 16, Loss: 5212.4027\n",
            "Epoch: 17, Loss: 4944.0445\n",
            "Epoch: 18, Loss: 4694.1981\n",
            "Epoch: 19, Loss: 4475.1006\n",
            "Epoch: 20, Loss: 4276.3810\n",
            "Epoch: 21, Loss: 4087.3041\n",
            "Epoch: 22, Loss: 3929.7430\n",
            "Epoch: 23, Loss: 3774.2124\n",
            "Epoch: 24, Loss: 3646.7703\n",
            "Epoch: 25, Loss: 3514.0105\n",
            "Epoch: 26, Loss: 3406.1459\n",
            "Epoch: 27, Loss: 3303.6108\n",
            "Epoch: 28, Loss: 3200.4137\n",
            "Epoch: 29, Loss: 3123.3815\n",
            "Epoch: 30, Loss: 3036.5681\n",
            "Epoch: 31, Loss: 2955.8705\n",
            "Epoch: 32, Loss: 2897.9081\n",
            "Epoch: 33, Loss: 2837.2712\n",
            "Epoch: 34, Loss: 2772.1834\n",
            "Epoch: 35, Loss: 2731.9357\n",
            "Epoch: 36, Loss: 2672.3260\n",
            "Epoch: 37, Loss: 2620.8913\n",
            "Epoch: 38, Loss: 2593.5725\n",
            "Epoch: 39, Loss: 2546.4723\n",
            "Epoch: 40, Loss: 2512.2600\n",
            "Epoch: 41, Loss: 2484.0604\n",
            "Epoch: 42, Loss: 2447.2470\n",
            "Epoch: 43, Loss: 2420.2391\n",
            "Epoch: 44, Loss: 2395.4209\n",
            "Epoch: 45, Loss: 2352.9744\n",
            "Epoch: 46, Loss: 2346.0206\n",
            "Epoch: 47, Loss: 2323.4722\n",
            "Epoch: 48, Loss: 2306.5041\n",
            "Epoch: 49, Loss: 2302.1059\n",
            "Epoch: 50, Loss: 2277.7815\n",
            "Epoch: 51, Loss: 2259.6947\n",
            "Epoch: 52, Loss: 2251.1032\n",
            "Epoch: 53, Loss: 2224.4494\n",
            "Epoch: 54, Loss: 2222.5752\n",
            "Epoch: 55, Loss: 2187.4849\n",
            "Epoch: 56, Loss: 2199.1354\n",
            "Epoch: 57, Loss: 2172.4825\n",
            "Epoch: 58, Loss: 2163.8269\n",
            "Epoch: 59, Loss: 2167.0140\n",
            "Epoch: 60, Loss: 2149.9057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Text Generation"
      ],
      "metadata": {
        "id": "kvR2c_26wd1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prediction(model, vocab, text, max_seq_length):\n",
        "\n",
        "    # tokenize\n",
        "    tokenized_text = word_tokenize(text.lower())\n",
        "\n",
        "    # text -> numerical indices\n",
        "    numerical_text = text_to_indices(tokenized_text, vocab)\n",
        "\n",
        "    # padding\n",
        "    padded_text = torch.tensor(\n",
        "        [0] * (max_seq_length  - len(numerical_text)) + numerical_text,\n",
        "        dtype=torch.long\n",
        "    ).unsqueeze(0)\n",
        "\n",
        "    # send padded_text to same device as model\n",
        "    device = next(model.parameters()).device\n",
        "    padded_text = padded_text.to(device)\n",
        "\n",
        "    # send to model\n",
        "    output = model(padded_text)\n",
        "\n",
        "    # predicted index\n",
        "    _, index = torch.max(output, dim=1)\n",
        "\n",
        "    #convert index to word\n",
        "    index_to_word = {idx: word for word, idx in vocab.items()}\n",
        "\n",
        "    predicted_word = index_to_word[index.item()]\n",
        "    return text + \" \" + predicted_word\n"
      ],
      "metadata": {
        "id": "O9f6DkX-ZM-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single prediction\n",
        "prediction(model, vocab, \"I had seen little of\", max_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VsRgcJysbGCg",
        "outputId": "625920ff-f75a-442d-fc84-bdeef340a2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I had seen little of holmes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction(model, vocab, \"remained in our lodgings\", max_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HyO_v_IzpZDN",
        "outputId": "45e4e09c-b2af-4e09-f380-1adfbfbb3910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'remained in our lodgings in'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate multiple words\n",
        "\n",
        "import time\n",
        "\n",
        "num_tokens = 10\n",
        "input_text = \"To Sherlock Holmes \"\n",
        "\n",
        "for i in range(num_tokens):\n",
        "  output_text = prediction(model, vocab, input_text, max_len_list)\n",
        "  print(output_text)\n",
        "  input_text = output_text\n",
        "  time.sleep(0.5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_JPACfEbNPo",
        "outputId": "5d8496c6-510b-45e2-e854-cb122057f970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To Sherlock Holmes  she\n",
            "To Sherlock Holmes  she is\n",
            "To Sherlock Holmes  she is always\n",
            "To Sherlock Holmes  she is always _the_\n",
            "To Sherlock Holmes  she is always _the_ woman\n",
            "To Sherlock Holmes  she is always _the_ woman .\n",
            "To Sherlock Holmes  she is always _the_ woman . i\n",
            "To Sherlock Holmes  she is always _the_ woman . i have\n",
            "To Sherlock Holmes  she is always _the_ woman . i have seldom\n",
            "To Sherlock Holmes  she is always _the_ woman . i have seldom heard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "JXsV4AnNXNnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Model Evaluation"
      ],
      "metadata": {
        "id": "iLbQoVjQw9Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate accuracy\n",
        "def calculate_accuracy(model, dataloader, device):\n",
        "    model.eval()  # set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in dataloader1:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "\n",
        "            # get model predictions\n",
        "            outputs = model(batch_x)\n",
        "\n",
        "            # get the predicted word indices\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "\n",
        "            # compare with actual labels\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy\n",
        "\n",
        "# compute accuracy\n",
        "accuracy = calculate_accuracy(model, dataloader, device)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Py7o0rJJc5pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dab86b-ab27-495f-a26b-00a8e5ca3da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 86.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bQnBuShXG5i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}